### Word embeddings
- [__lecture slides__](https://github.com/yandexdataschool/nlp_course/blob/master/resources/slides/lecture1_word_embeddings.pdf)


### Practice & homework
The practice for this week takes place in notebooks. Just open them and follow instructions from there.
* __Seminar:__ `./seminar.ipynb`
* __Homework:__ `./homework.ipynb`

Unless explicitly said otherwise, all subsequent weeks follow the same pattern (notebook with instructions).

If you have any difficulties with notebooks, just open them in [colab](https://colab.research.google.com/github/yandexdataschool/nlp_course/blob/master/week1_embeddings/seminar.ipynb).

### More materials (optional)
* Video lectures from Stanford CS224N - [__intro__](https://www.youtube.com/watch?v=OQQ-W_63UgQ), [__embeddings__](https://www.youtube.com/watch?v=ERibwqs9p38) (english)
* On hierarchical & sampled softmax estimation for word2vec [page](http://ruder.io/word-embeddings-softmax/)
* GloVe project [page](https://nlp.stanford.edu/projects/glove/)
* FastText project [repo](https://github.com/facebookresearch/fastText)
* Semantic change over time - oberved through word embeddings - [arxiv](https://arxiv.org/pdf/1605.09096.pdf)
* Another cool link that you could have shared, but decided to hesitate. Or did you?
